This project focuses on developing an image-based dress search system that enhances the online fashion shopping experience by allowing users to search for dresses using an image instead of text. Traditional search methods often struggle to capture visual attributes like patterns, textures, and colorsâ€”key elements in fashion. To solve this, the system uses computer vision techniques including SIFT (for shape and structure), Local Binary Patterns (LBP) (for texture), and color histograms (for color distribution) to extract features from a user-uploaded query image. These features are then compared with precomputed features from a dataset of dress images to find and display the top 5 visually similar matches. The system is implemented in Python using OpenCV, scikit-image, and pandas, and runs in Google Colab for accessibility. The goal is to make online dress shopping more intuitive, efficient, and visually driven. While the system performs well in identifying similar dresses, it also highlights areas for improvement, such as handling lighting variations and dataset diversity. This solution is lightweight and interpretable, offering a practical and scalable tool for fashion e-commerce platforms.
















